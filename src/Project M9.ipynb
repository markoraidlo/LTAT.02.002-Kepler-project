{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project M9: Exoplanet detection using the transit method\n",
    "\n",
    "Marko Raidlo, Raido Everest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will uniformly use random state = 3 for replicability of results.\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "#plt.rcParams['figure.dpi'] = 1000\n",
    "plt.rcParams.update({'font.size': 30})\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import ndimage, fft\n",
    "from sklearn.preprocessing import normalize, StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('exoTrain.csv')\n",
    "test = pd.read_csv('exoTest.csv')\n",
    "    \n",
    "train.columns = [train.columns[i].replace(\"FLUX.\", \"\") for i in range(len(train.columns))]\n",
    "test.columns = [test.columns[i].replace(\"FLUX.\", \"\") for i in range(len(test.columns))]\n",
    "    \n",
    "#Replacing 2s and 1s with 1s and 0s.\n",
    "train.LABEL = train.LABEL.replace(1, 0)\n",
    "train.LABEL = train.LABEL.replace(2, 1)\n",
    "test.LABEL = test.LABEL.replace(1, 0)\n",
    "test.LABEL = test.LABEL.replace(2, 1)\n",
    "    \n",
    "#X and Y datasets\n",
    "train_X = train.drop('LABEL', axis=1)\n",
    "train_Y = train[\"LABEL\"]\n",
    "\n",
    "test_X = test.drop('LABEL', axis=1)\n",
    "test_Y = test[\"LABEL\"]\n",
    "\n",
    "train_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier(df):\n",
    "        return np.abs(fft(df, n=df.size))\n",
    "\n",
    "def pre_process(df):\n",
    "    #Preprocessing method applies:\n",
    "    # Fourier transform\n",
    "    # Normalization\n",
    "    # Gaussian filter\n",
    "    # Standardization\n",
    "    \n",
    "    #Fourier\n",
    "    df_copy = df.copy()\n",
    "    df_copy = df_copy.apply(fourier ,axis=1)\n",
    "    \n",
    "    df_copy = pd.DataFrame(df_copy.tolist())\n",
    "    df_copy  = df_copy.iloc[:,0:df_copy.shape[1]//2]\n",
    "    \n",
    "    # Normalize\n",
    "    df_copy = pd.DataFrame(normalize(df_copy))\n",
    "\n",
    "    # Gaussian filter to smooth out data\n",
    "    df_copy = ndimage.filters.gaussian_filter(df_copy, sigma=10)\n",
    "\n",
    "    # Standardize X data\n",
    "    std_scaler = StandardScaler()\n",
    "    df_copy = std_scaler.fit_transform(df_copy)\n",
    "    \n",
    "    return pd.DataFrame(df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre process plot\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.title(\"Exoplanet\")\n",
    "train_X.iloc[1].plot()\n",
    "plt.ylabel(\"FLUX\")\n",
    "plt.subplot(212)\n",
    "plt.title(\"No exoplanet\")\n",
    "train_X.iloc[3213].plot()\n",
    "plt.ylabel(\"FLUX\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "#plt.savefig('fig1.png', dpi = 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing data\n",
    "train_X = pre_process(train_X)\n",
    "test_X = pre_process(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Post process plot\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.title(\"Exoplanet\")\n",
    "train_X.iloc[1].plot()\n",
    "plt.ylabel(\"Level\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.subplot(212)\n",
    "plt.title(\"No exoplanet\")\n",
    "train_X.iloc[3213].plot()\n",
    "plt.ylabel(\"Level\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "#plt.savefig('fig2.png', dpi = 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exoplanet star results\n",
    "plt.subplot(221)\n",
    "train_X.iloc[12].plot()\n",
    "plt.subplot(222)\n",
    "train_X.iloc[21].plot()\n",
    "plt.subplot(223)\n",
    "train_X.iloc[23].plot()\n",
    "plt.subplot(224)\n",
    "train_X.iloc[32].plot()\n",
    "#plt.savefig('fig3.png', dpi = 1000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non exoplanet star results\n",
    "plt.subplot(221)\n",
    "train_X.iloc[1111].plot()\n",
    "plt.subplot(222)\n",
    "train_X.iloc[2231].plot()\n",
    "plt.subplot(223)\n",
    "train_X.iloc[4512].plot()\n",
    "plt.subplot(224)\n",
    "train_X.iloc[1233].plot()\n",
    "#plt.savefig('fig4.png', dpi = 1000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation method:\n",
    "\n",
    "def evaluate(model):\n",
    "    train_result =  model.predict(train_X)\n",
    "    test_result = model.predict(test_X)\n",
    "    confm_train = confusion_matrix(train_Y, train_result)\n",
    "    confm_test = confusion_matrix(test_Y, test_result)\n",
    "    \n",
    "    acc_train = accuracy_score(train_Y, train_result)\n",
    "    acc_test = accuracy_score(test_Y, test_result)\n",
    "    pre_train = precision_score(train_Y, train_result)\n",
    "    pre_test = precision_score(test_Y, test_result)\n",
    "    rec_train = recall_score(train_Y, train_result)\n",
    "    rec_test = recall_score(test_Y, test_result)\n",
    "    auc_train = roc_auc_score(train_Y, train_result)\n",
    "    auc_test = roc_auc_score(test_Y, test_result)\n",
    "    \n",
    "    print(\"------------------Evaluation------------------\")\n",
    "    print(\"On training set:\")\n",
    "    print(\"Accuracy:\", acc_train)\n",
    "    print(\"Precision:\", pre_train)\n",
    "    print(\"Recall:\", rec_train)\n",
    "    print(\"AUC score:\", auc_train)\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confm_train)\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(\"On test set:\")\n",
    "    print(\"Accuracy:\", acc_test)\n",
    "    print(\"Precision:\", pre_test)\n",
    "    print(\"Recall:\", rec_test)\n",
    "    print(\"AUC score:\", auc_test)\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confm_test)\n",
    "    print(\"--------------End of valuation----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log = LogisticRegression(random_state = 3, solver='lbfgs')\n",
    "model_log.fit(train_X, train_Y)\n",
    "\n",
    "evaluate(model_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = svm.LinearSVC(random_state = 3, max_iter = 1000)\n",
    "model_svm.fit(train_X, train_Y)\n",
    "evaluate(model_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = KNeighborsClassifier(n_neighbors = 9, weights = 'distance')\n",
    "model_knn.fit(train_X, train_Y)\n",
    "\n",
    "evaluate(model_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree = DecisionTreeClassifier(random_state = 3)\n",
    "model_tree.fit(train_X, train_Y)\n",
    "\n",
    "evaluate(model_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forest = RandomForestClassifier(random_state = 3, n_estimators=5, max_depth=3)\n",
    "model_forest.fit(train_X, train_Y)\n",
    "\n",
    "evaluate(model_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=1000, learning_rate=1.0, max_depth=2, random_state=3).fit(train_X, train_Y)\n",
    "\n",
    "evaluate(clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
